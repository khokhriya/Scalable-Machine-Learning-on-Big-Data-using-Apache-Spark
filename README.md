# Scalable-Machine-Learning-on-Big-Data-using-Apache-Spark
Scalable Machine Learning on Big Data using Apache Spark
## Introduction
This is an introduction to Apache Spark. You'll learn how Apache Spark internally works and how to use it for data processing. RDD, the low level API is introduced in conjunction with parallel programming / functional programming. Then, different types of data storage solutions are contrasted. Finally, Apache Spark SQL and the optimizer Tungsten and Catalyst are explained.

## Scaling Math for Statistics on Apache Spark
Applying basic statistical calculations using the Apache Spark RDD API in order to experience how parallelization in Apache Spark works
* Averages
* Standard deviation
* Skewness
* Kurtosis
* Covariance, Covariance matrices, correlation
* Plotting with ApacheSpark and python's matplotlib
* Dimensionality reduction
* PCA5
